{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.first get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Analyst” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3.Then click the search button.\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "5.Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-428e645c400f>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\") \n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg') \n",
    "search_field_designation.send_keys(\"Data Analyst\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "company_name[0:2]\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "df=pd.DataFrame({\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_title\":job_title[0:10]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Liventus, Inc.</td>\n",
       "      <td>Bangalore/Bengaluru(2nd Phase JP Nagar)</td>\n",
       "      <td>Senior Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>(6 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst, Component Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>Rockwell Automation</td>\n",
       "      <td>Bangalore/Bengaluru(Ulsoor)</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1-5 Yrs</td>\n",
       "      <td>(151 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Business Analyst / Data Analyst - SQL Queries,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3-6 Yrs</td>\n",
       "      <td>WEIWO Communication Pvt. Ltd.</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1-3 Yrs</td>\n",
       "      <td>(25 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7-10 Yrs</td>\n",
       "      <td>Rivera Manpower Services</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Mumbai, Bangalore/Bengaluru</td>\n",
       "      <td>Business Data Analyst - MIS &amp; Reporting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5-8 Yrs</td>\n",
       "      <td>(539 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Lead Data Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2-3 Yrs</td>\n",
       "      <td>Flipkart Internet Private Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Data Analyst</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  experience_required                       company_name  \\\n",
       "0             5-8 Yrs                     Liventus, Inc.   \n",
       "1             2-3 Yrs                        (6 Reviews)   \n",
       "2             5-8 Yrs                Rockwell Automation   \n",
       "3             1-5 Yrs                      (151 Reviews)   \n",
       "4             3-6 Yrs      WEIWO Communication Pvt. Ltd.   \n",
       "5             1-3 Yrs                       (25 Reviews)   \n",
       "6            7-10 Yrs           Rivera Manpower Services   \n",
       "7             3-8 Yrs              Philips India Limited   \n",
       "8             5-8 Yrs                      (539 Reviews)   \n",
       "9             2-3 Yrs  Flipkart Internet Private Limited   \n",
       "\n",
       "                              job_location  \\\n",
       "0  Bangalore/Bengaluru(2nd Phase JP Nagar)   \n",
       "1                      Bangalore/Bengaluru   \n",
       "2              Bangalore/Bengaluru(Ulsoor)   \n",
       "3                      Bangalore/Bengaluru   \n",
       "4                      Bangalore/Bengaluru   \n",
       "5                      Bangalore/Bengaluru   \n",
       "6                      Bangalore/Bengaluru   \n",
       "7              Mumbai, Bangalore/Bengaluru   \n",
       "8                      Bangalore/Bengaluru   \n",
       "9                      Bangalore/Bengaluru   \n",
       "\n",
       "                                           job_title  \n",
       "0                                Senior Data Analyst  \n",
       "1                Data Analyst, Component Engineering  \n",
       "2                                       Data Analyst  \n",
       "3  Business Analyst / Data Analyst - SQL Queries,...  \n",
       "4                                       Data Analyst  \n",
       "5                                       Data Analyst  \n",
       "6                                       Data Analyst  \n",
       "7            Business Data Analyst - MIS & Reporting  \n",
       "8                                  Lead Data Analyst  \n",
       "9                                       Data Analyst  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created program for Data Analyst job position with required experience, company name, job location and job title. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, full job-description. You have to scrape first 10 jobs data. This task will be done in following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.first get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Scientist” in “Skill,Designations,Companies” field and enter “Bangalore” in “enter the location” field.\n",
    "3.Then click the search button.\n",
    "4.Then scrape the data for the first 10 jobs results you get.\n",
    "5.Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-73ddac37eb79>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:443: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   \n",
    "search_field_location=driver.find_element_by_id('qsb-location-sugg')  \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "search_field_location.send_keys(\"Bangalore\")\n",
    "\n",
    "\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "full_job_description=[]\n",
    "\n",
    "\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "time.sleep(4)        \n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "\n",
    "urls=[i.get_attribute(\"href\")for i in driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")]\n",
    "for url in urls[0:10]:\n",
    "    try:\n",
    "        \n",
    "        driver.get(url)\n",
    "        raw_description=driver.find_element_by_xpath(\"//section[@class='job-desc']/div[1]\").text\n",
    "        description=raw_description.replace(\"Contact Person\",\"@@@@@\")\n",
    "        description= description.split(\"@@@@@\")\n",
    "        full_job_description.append(description[0])\n",
    "    except NoSuchElementException :\n",
    "        full_job_description.append(\"---\")\n",
    "        \n",
    "        \n",
    " \n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"company_name\":company_name[0:10],\"job_location\":job_location[0:10],\n",
    "                \"job_description\":full_job_description[0:10]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Job Responsibilities\\nUse predictive modeling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IDM - Lead Data Scientist</td>\n",
       "      <td>(539 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Your responsibilities\\nEnsure strategic direct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior/Lead Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Hyderabad/Secunderabad, Chennai, Bangalore/Ben...</td>\n",
       "      <td>Responsibilities\\nIdentify valuable data sourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>(539 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>In this role, you have the opportunity to\\nPro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - Business Analytics</td>\n",
       "      <td>AUREUSTECH SYSTEMS PRIVATE LIMITED</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Support business in their decision making need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>In this role, you have the opportunity to\\nPro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>(539 Reviews)</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Kwalee is one of the world's leading multiplat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Scientist- (Counterparty Credit r...</td>\n",
       "      <td>(539 Reviews)</td>\n",
       "      <td>Hyderabad/Secunderabad, Ahmedabad, Bangalore/B...</td>\n",
       "      <td>---</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior/ Lead Data Scientist</td>\n",
       "      <td>Philips India Limited</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Responsibilities\\nProvide advanced analytical ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title  \\\n",
       "0                            Senior Data Scientist I   \n",
       "1                          IDM - Lead Data Scientist   \n",
       "2                         Senior/Lead Data Scientist   \n",
       "3                           Principal Data Scientist   \n",
       "4                Data Scientist - Business Analytics   \n",
       "5                                     Data Scientist   \n",
       "6                              Senior Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Data Analyst/Scientist- (Counterparty Credit r...   \n",
       "9                        Senior/ Lead Data Scientist   \n",
       "\n",
       "                         company_name  \\\n",
       "0               Philips India Limited   \n",
       "1                       (539 Reviews)   \n",
       "2               Philips India Limited   \n",
       "3                       (539 Reviews)   \n",
       "4  AUREUSTECH SYSTEMS PRIVATE LIMITED   \n",
       "5               Philips India Limited   \n",
       "6                       (539 Reviews)   \n",
       "7               Philips India Limited   \n",
       "8                       (539 Reviews)   \n",
       "9               Philips India Limited   \n",
       "\n",
       "                                        job_location  \\\n",
       "0                                Bangalore/Bengaluru   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Hyderabad/Secunderabad, Chennai, Bangalore/Ben...   \n",
       "3                                Bangalore/Bengaluru   \n",
       "4                                Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6                                Bangalore/Bengaluru   \n",
       "7                                Bangalore/Bengaluru   \n",
       "8  Hyderabad/Secunderabad, Ahmedabad, Bangalore/B...   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                                     job_description  \n",
       "0  Job Responsibilities\\nUse predictive modeling ...  \n",
       "1  Your responsibilities\\nEnsure strategic direct...  \n",
       "2  Responsibilities\\nIdentify valuable data sourc...  \n",
       "3  In this role, you have the opportunity to\\nPro...  \n",
       "4  Support business in their decision making need...  \n",
       "5  In this role, you have the opportunity to\\nPro...  \n",
       "6  Kwalee is one of the world's leading multiplat...  \n",
       "7                                                ---  \n",
       "8                                                ---  \n",
       "9  Responsibilities\\nProvide advanced analytical ...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created the program of data scientist job with job title,company name,job location and job description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below: You have to use the location and salary filter. You have to scrape data for “Data Scientist” designation for first 10 job results. You have to scrape the job-title, job-location, company_name, experience_required. The location filter to be used is “Delhi/NCR” The salary filter to be used is “3-6” lakhs The task will be done as shown in the below steps:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.first get the webpage https://www.naukri.com/\n",
    "2.Enter “Data Scientist” in “Skill,Designations,Companies” field .\n",
    "3.Then click the search button.\n",
    "4.Then apply the location filter and salary filter by checking the respective boxes\n",
    "5.Then scrape the data for the first 10 jobs results you get.\n",
    "6.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-9646240ffcd5>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:443: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.naukri.com/\"\n",
    "driver.get(url)\n",
    "time.sleep(6)\n",
    "\n",
    "\n",
    "\n",
    "search_field_designation=driver.find_element_by_id(\"qsb-keyword-sugg\")   \n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//div[@class='search-btn']/button\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "\n",
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "loc=driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[2]/div[2]/div[2]/label/p\")\n",
    "loc.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "slry_box = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[3]/div[2]/div[2]/label/p\")\n",
    "slry_box.click()\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "titles=driver.find_elements_by_xpath(\"//a[@class='title fw500 ellipsis']\")\n",
    "for i in titles:\n",
    "    if i.text is None :\n",
    "        job_title.append(\"--\") \n",
    "    else:\n",
    "        job_title.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "locations=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi location']/span[1]\")\n",
    "for i in locations:\n",
    "    if i.text is None :\n",
    "        job_location.append(\"--\") \n",
    "    else:\n",
    "        job_location.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    " \n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='mt-7 companyInfo subheading lh16']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "experience=driver.find_elements_by_xpath(\"//li[@class='fleft grey-text br2 placeHolderLi experience']/span[1]\")\n",
    "for i in experience:\n",
    "    if i.text is None :\n",
    "            experience_required.append(\"--\") \n",
    "    else:\n",
    "            experience_required.append(i.text)\n",
    "            \n",
    "time.sleep(3)            \n",
    " \n",
    "df=pd.DataFrame({\"job_title\":job_title[0:10],\"experience_required\":experience_required[0:10],\"company_name\":company_name[0:10],\n",
    "                 \"job_location\":job_location[0:10]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>experience_required</th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist - Text NLP | Noida</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "      <td>Acidaes Solutions Pvt. Ltd.</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "      <td>(66 Reviews)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Machine Learning/NLP</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "      <td>TalPro</td>\n",
       "      <td>Noida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "      <td>(13 Reviews)</td>\n",
       "      <td>New Delhi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>(2 Reviews)</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title experience_required  \\\n",
       "0    Data Scientist / Data Analyst -Business Analyst             0-3 Yrs   \n",
       "1                  Data Scientist - Text NLP | Noida             3-5 Yrs   \n",
       "2              Data Scientist - Machine Learning/NLP             2-6 Yrs   \n",
       "3              Data Scientist - Machine Learning/NLP             2-4 Yrs   \n",
       "4                                     Data Scientist             3-8 Yrs   \n",
       "5  Data analytics / Data scientist intern (work f...             0-5 Yrs   \n",
       "6              Chaayos is Looking For Data Scientist             0-5 Yrs   \n",
       "7                                     Data Scientist             3-7 Yrs   \n",
       "8       We are hiring- Data Scientist +Python- Noida             4-7 Yrs   \n",
       "9                                     Data Scientist             4-7 Yrs   \n",
       "\n",
       "                            company_name  \\\n",
       "0     Inflexion Analytix Private Limited   \n",
       "1            Acidaes Solutions Pvt. Ltd.   \n",
       "2                           (66 Reviews)   \n",
       "3                                 TalPro   \n",
       "4                                 TalPro   \n",
       "5  NEC CORPORATION INDIA PRIVATE LIMITED   \n",
       "6                           (13 Reviews)   \n",
       "7                         TalkValley LLC   \n",
       "8                            (2 Reviews)   \n",
       "9  Chaayos (Sunshine Teahouse Pvt. Ltd.)   \n",
       "\n",
       "                                        job_location  \n",
       "0  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...  \n",
       "1                                              Noida  \n",
       "2                                   Gurgaon/Gurugram  \n",
       "3                                   Gurgaon/Gurugram  \n",
       "4                                              Noida  \n",
       "5          Kolkata, Bangalore/Bengaluru, Delhi / NCR  \n",
       "6                                          New Delhi  \n",
       "7      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru  \n",
       "8               Noida, Gurgaon/Gurugram, Delhi / NCR  \n",
       "9                                   Gurgaon/Gurugram  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have created the programme for data scientist jobs available having job title and with experience required, company name and job location also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4: Write a python program to scrape data for first 10 job results for Data scientist Designation in Noida location. You have to scrape company_name, No. of days ago when job was posted, Rating of the company. This task will be done in following steps:\n",
    "\n",
    "1.first get the webpage https://www.glassdoor.co.in/index.htm\n",
    "2.Enter “Data Scientist” in “Job Title,Keyword,Company” field and enter “Noida” in “location” field.\n",
    "3.Then click the search button. You will land up in the below page:\n",
    "4.Then scrape the data for the first 10 jobs results you get in the above shown page. WEB SCRAPING ASSIGNMENT-2 .\n",
    "5.Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-4116fd1c2e79>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"}\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x0023CEBB+1232571]\n\tOrdinal0 [0x002668F2+1403122]\n\tOrdinal0 [0x00255EBA+1334970]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-4967389f182b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#job search bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msearch_field_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#location search bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m    483\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"find_element_by_* commands are deprecated. Please use find_element() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1154\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    402\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"}\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x0023CEBB+1232571]\n\tOrdinal0 [0x002668F2+1403122]\n\tOrdinal0 [0x00255EBA+1334970]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n"
     ]
    }
   ],
   "source": [
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")  #location search bar\n",
    "search_field_location.clear()   \n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "\n",
    "company_ratings=[]\n",
    "company_name=[]\n",
    "days_ago=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "companies=driver.find_elements_by_xpath(\"//div[@class='d-flex justify-content-between align-items-start']/a\")\n",
    "for i in companies:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\") \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "ratings=driver.find_elements_by_xpath(\"//span[@class='css-19pjha7 e1cjmv6j1']\")\n",
    "for i in ratings:\n",
    "    if i.text is None :\n",
    "        company_ratings.append(\"--\") \n",
    "    else:\n",
    "        company_ratings.append(i.text)\n",
    "        \n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "days=driver.find_elements_by_xpath(\"//div[@class='d-flex align-items-end pl-std css-mi55ob']\")\n",
    "for i in days:\n",
    "    if i.text is None :\n",
    "        days_ago.append(\"--\") \n",
    "    else:\n",
    "        days_ago.append(i.text)\n",
    "        \n",
    "        \n",
    "time.sleep(3)        \n",
    " \n",
    "df=pd.DataFrame({\"company_name\":company_name[0:10],\"company_ratings\":company_ratings[0:10],\"days_ago\":days_ago[0:10]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5: Write a python program to scrape the salary data for Data Scientist designation in Noida location. You have to scrape Company name, Number of salaries, Average salary, Min salary, Max Salary. The above task will be, done as shown in the below steps:\n",
    "\n",
    "1.first get the webpage https://www.glassdoor.co.in/Salaries/index.htm\n",
    "2.Enter “Data Scientist” in Job title field and “Noida” in location field.\n",
    "3.Click the search button.\n",
    "4.After that you will land on the below page You have to scrape whole data from this webpage\n",
    "5.Scrape data for first 10 companies. Scrape the min salary, max salary, company name, Average salary and rating of the company. 6.Store the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-19-4116fd1c2e79>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(4)\n",
    "\n",
    "url = \"https://www.glassdoor.co.in/index.htm\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"}\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x0023CEBB+1232571]\n\tOrdinal0 [0x002668F2+1403122]\n\tOrdinal0 [0x00255EBA+1334970]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-2212202b2832>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#job search bar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msearch_field_designation\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data Scientist\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_xpath\u001b[1;34m(self, xpath)\u001b[0m\n\u001b[0;32m    482\u001b[0m         \"\"\"\n\u001b[0;32m    483\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"find_element_by_* commands are deprecated. Please use find_element() instead\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_xpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxpath\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mWebElement\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1153\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m   1154\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1155\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    402\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\"}\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x0023CEBB+1232571]\n\tOrdinal0 [0x002668F2+1403122]\n\tOrdinal0 [0x00255EBA+1334970]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n"
     ]
    }
   ],
   "source": [
    "search_field_designation=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[1]//div[1]//input\")  #job search bar\n",
    "search_field_designation.send_keys(\"Data Scientist\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "for i in range(9):\n",
    "    driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\").send_keys(Keys.BACK_SPACE)\n",
    "\n",
    "\n",
    "search_field_location=driver.find_element_by_xpath(\"//div[@class='d-flex flex-row align-items-center']//div[3]//div[1]//input\")  \n",
    "search_field_location.send_keys(\"Noida\")\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "option = driver.find_element_by_xpath(\"//div[@class='selectedLabel']\")\n",
    "option.click()\n",
    "time.sleep(2)\n",
    "salary_option = driver.find_element_by_xpath(\"//div[@class='dropDownOptionsContainer']//ul//li[3]\")\n",
    "salary_option.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='gd-ui-button ml-std col-auto SearchStyles__newSearchButton css-iixdfr']\")\n",
    "search_button.click()\n",
    "\n",
    "\n",
    "company_name=[]\n",
    "min_salaries=[]\n",
    "max_salaries=[]\n",
    "average_salaries=[]\n",
    "no_of_salaries=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "company=driver.find_elements_by_xpath(\"//div[@data-test='job-info']/p[2]\")\n",
    "for i in company:\n",
    "    if i.text is None :\n",
    "        company_name.append(\"--\")      \n",
    "    else:\n",
    "        company_name.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "min_salary = driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']//span[1]\")\n",
    "for i in min_salary:\n",
    "    if i.text is None:\n",
    "        min_salaries.append(\"--\")\n",
    "    else:\n",
    "        min_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "max_salary=driver.find_elements_by_xpath(\"//div[@class='common__RangeBarStyle__values d-flex justify-content-between ']/span[2]\")\n",
    "for i in max_salary:\n",
    "    if i.text is None :\n",
    "        max_salaries.append(\"--\") \n",
    "    else:\n",
    "        max_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "average_salary=driver.find_elements_by_xpath(\"//div[@class='col-2 d-none d-md-flex flex-row justify-content-end']/strong\")\n",
    "for i in average_salary:\n",
    "    if i.text is None :\n",
    "        average_salaries.append(\"--\") \n",
    "    else:\n",
    "        average_salaries.append(i.text)\n",
    "        \n",
    "time.sleep(3)        \n",
    "\n",
    "no_of_salary=driver.find_elements_by_xpath(\"//p[@class='css-1uyte9r css-1kuy7z7 m-0 ']\")\n",
    "for i in no_of_salary:\n",
    "    if i.text is None :\n",
    "        no_of_salaries.append(\"--\") \n",
    "    else:\n",
    "        no_of_salaries.append(i.text)\n",
    "        \n",
    "        \n",
    " # creating the dataframe from the scraped data \n",
    "df=pd.DataFrame({\"company_name\":company_name,\"min_salaries\":min_salaries,\"max_salaries\":max_salaries,\n",
    "                 \"average_salaries\":average_salaries,\"no_of_salaries\":no_of_salaries})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "        \n",
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "4.Discount To scrape the data you have to go through following steps:\n",
    "5.Go to flipkart webpage by url https://www.flipkart.com/\n",
    "6.Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "7.after that you will reach to a webpage having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "8.after scraping data from the first page, go to the “Next” Button at the bottom of the page , then click on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-c5f481bd15c4>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n"
     ]
    },
    {
     "ename": "ElementClickInterceptedException",
     "evalue": "Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_36HLxm col col-3-5\">...</div>\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x00242DEE+1256942]\n\tOrdinal0 [0x002410EE+1249518]\n\tOrdinal0 [0x0023EF1F+1240863]\n\tOrdinal0 [0x0023DE18+1236504]\n\tOrdinal0 [0x00233767+1193831]\n\tOrdinal0 [0x00255E83+1334915]\n\tOrdinal0 [0x00233586+1193350]\n\tOrdinal0 [0x00255F6A+1335146]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-c5f481bd15c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#locating the button and clicking it toh search for sunglasses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mbutton\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_class_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'L0Z3Pu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mbutton\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36mclick\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m         \u001b[1;34m\"\"\"Clicks the element.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCLICK_ELEMENT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    691\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 693\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    694\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    695\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    398\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    401\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    402\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    234\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mElementClickInterceptedException\u001b[0m: Message: element click intercepted: Element <button class=\"L0Z3Pu\" type=\"submit\">...</button> is not clickable at point (556, 28). Other element would receive the click: <div class=\"_36HLxm col col-3-5\">...</div>\n  (Session info: chrome=91.0.4472.114)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00373733+2504499]\n\tOrdinal0 [0x0030C401+2081793]\n\tOrdinal0 [0x00212628+1058344]\n\tOrdinal0 [0x00242DEE+1256942]\n\tOrdinal0 [0x002410EE+1249518]\n\tOrdinal0 [0x0023EF1F+1240863]\n\tOrdinal0 [0x0023DE18+1236504]\n\tOrdinal0 [0x00233767+1193831]\n\tOrdinal0 [0x00255E83+1334915]\n\tOrdinal0 [0x00233586+1193350]\n\tOrdinal0 [0x00255F6A+1335146]\n\tOrdinal0 [0x00264CDB+1395931]\n\tOrdinal0 [0x00255D4B+1334603]\n\tOrdinal0 [0x002322B4+1188532]\n\tOrdinal0 [0x00233149+1192265]\n\tGetHandleVerifier [0x004EFB8C+1512252]\n\tGetHandleVerifier [0x0059B0DF+2214031]\n\tGetHandleVerifier [0x003F4BC3+484211]\n\tGetHandleVerifier [0x003F3E69+480793]\n\tOrdinal0 [0x0031218D+2105741]\n\tOrdinal0 [0x003166E8+2123496]\n\tOrdinal0 [0x00316827+2123815]\n\tOrdinal0 [0x0031FB73+2161523]\n\tBaseThreadInitThunk [0x755AFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77007A9E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77007A6E+238]\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the search bar\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.send_keys('sunglasses')\n",
    "\n",
    "time.sleep(2)\n",
    "#locating the button and clicking it toh search for sunglasses\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "#creating the empty list\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "#scrapping the required details\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):#for loop for scrapping 4 page\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')#scraping brands name by class name='_2WkVRV'\n",
    "    for i in brands:\n",
    "        brand.append(i.text)#appending the text in Brand list\n",
    "    desc=driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')#scraping description from the xpath\n",
    "    for i in desc:\n",
    "        description.append(i.text)#appending the description in list\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")# scraping the price from the xpath\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")# scraping the discount from the xpath\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))#getting the link from the list for next page\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "\n",
    "time.sleep(3)        \n",
    "#creating a dataframe\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "#printing dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q7: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb-includesearpods-poweradapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace. you have to scrape the below mention attributes. These are\n",
    "\n",
    "1.Rating\n",
    "2.Review_summary\n",
    "3.Full review You have to scrape this data for first 100 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-42cc1591eba9>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of Stars</th>\n",
       "      <th>Short Review</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Iphone is just awesome.. battery backup is ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Best budget Iphone till date ❤️ go for it guys...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Excellent camera, good performance, no lag. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>It’s been almost a month since I have been usi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good choice</td>\n",
       "      <td>So far it’s been an AMAZING experience coming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>iphone 11 is a very good phone to buy only if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>It’s a must buy who is looking for an upgrade ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Value for money❤️❤️\\nIts awesome mobile phone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>What a camera .....just awesome ..you can feel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Number of Stars        Short Review  \\\n",
       "0                5  Highly recommended   \n",
       "1                5    Perfect product!   \n",
       "2                5   Worth every penny   \n",
       "3                5      Simply awesome   \n",
       "4                5   Worth every penny   \n",
       "..             ...                 ...   \n",
       "95               4         Good choice   \n",
       "96               5  Highly recommended   \n",
       "97               5    Perfect product!   \n",
       "98               5    Perfect product!   \n",
       "99               5  Highly recommended   \n",
       "\n",
       "                                          Full Review  \n",
       "0   What a camera .....just awesome ..you can feel...  \n",
       "1   Iphone is just awesome.. battery backup is ver...  \n",
       "2   Best budget Iphone till date ❤️ go for it guys...  \n",
       "3   Excellent camera, good performance, no lag. Th...  \n",
       "4   It’s been almost a month since I have been usi...  \n",
       "..                                                ...  \n",
       "95  So far it’s been an AMAZING experience coming ...  \n",
       "96  iphone 11 is a very good phone to buy only if ...  \n",
       "97  It’s a must buy who is looking for an upgrade ...  \n",
       "98  Value for money❤️❤️\\nIts awesome mobile phone ...  \n",
       "99  What a camera .....just awesome ..you can feel...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/product-reviews/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "urls=[]\n",
    "short_review=[]\n",
    "complete_review=[]\n",
    "stars=[]\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "for i in range(10):\n",
    "    url=driver.find_element_by_xpath(\"//a[@class='ge-49M']\").get_attribute('href')\n",
    "    driver.get(url)\n",
    "    \n",
    "    for j in driver.find_elements_by_xpath(\"//div[@class='_3LWZlK _1BLPMq']\"):\n",
    "        stars.append(j.text)\n",
    "    \n",
    "    for k in driver.find_elements_by_xpath(\"//p[@class='_2-N8zT']\"):\n",
    "        short_review.append(k.text)\n",
    "    \n",
    "    for l in driver.find_elements_by_xpath(\"//div[@class='t-ZTKy']/div/div\"):\n",
    "        complete_review.append(l.text)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "df=pd.DataFrame({'Number of Stars': stars,\n",
    "                'Short Review': short_review,\n",
    "               'Full Review': complete_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we have created the programme for 100 data review's from flipcart with no. of stars, short review and full review."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q8:Scrape data for first 100 sneakers you find when you visit flipkart.comand search for “sneakers” in the search field.You have to scrape 4 attributes of each sneaker :\n",
    "1.Brand\n",
    "2.Product Description\n",
    "3.Price\n",
    "4.discount % Also note that all the steps required during scraping should be done through code only and not manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-8f06841d4e1f>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:683: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:702: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alfiya</td>\n",
       "      <td>Slyde Knit IDP Sneakers For Men  (Black, Grey)</td>\n",
       "      <td>₹377</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Sneakers For Men  (White)</td>\n",
       "      <td>₹748</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robbie jones</td>\n",
       "      <td>Cipramo Sneakers Long Shoes Sneakers For Men  ...</td>\n",
       "      <td>₹379</td>\n",
       "      <td>62% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KULP</td>\n",
       "      <td>mnnu casual running shoes, walking shoes, Snea...</td>\n",
       "      <td>₹399</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Poise Perf V1 IDP Sneakers For Men  (Grey)</td>\n",
       "      <td>₹473</td>\n",
       "      <td>68% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>WRIZT</td>\n",
       "      <td>Sneakers For Men  (Red, White)</td>\n",
       "      <td>₹279</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Axter</td>\n",
       "      <td>Respin SL Sneakers For Men  (Black)</td>\n",
       "      <td>₹379</td>\n",
       "      <td>72% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>D-SNEAKERZ</td>\n",
       "      <td>Sneakers For Men  (Navy)</td>\n",
       "      <td>₹384</td>\n",
       "      <td>61% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Absolute comfort</td>\n",
       "      <td>New style Sneakers For Men  (White, Black)</td>\n",
       "      <td>₹199</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PUMA</td>\n",
       "      <td>Smart Sneakers For Men  (Black)</td>\n",
       "      <td>₹1,538</td>\n",
       "      <td>45% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                        Description  \\\n",
       "0             Alfiya     Slyde Knit IDP Sneakers For Men  (Black, Grey)   \n",
       "1           CALCADOS                          Sneakers For Men  (White)   \n",
       "2       Robbie jones  Cipramo Sneakers Long Shoes Sneakers For Men  ...   \n",
       "3               KULP  mnnu casual running shoes, walking shoes, Snea...   \n",
       "4             Chevit         Poise Perf V1 IDP Sneakers For Men  (Grey)   \n",
       "..               ...                                                ...   \n",
       "95             WRIZT                     Sneakers For Men  (Red, White)   \n",
       "96             Axter                Respin SL Sneakers For Men  (Black)   \n",
       "97        D-SNEAKERZ                           Sneakers For Men  (Navy)   \n",
       "98  Absolute comfort         New style Sneakers For Men  (White, Black)   \n",
       "99              PUMA                    Smart Sneakers For Men  (Black)   \n",
       "\n",
       "     Price Discount  \n",
       "0     ₹377  62% off  \n",
       "1     ₹748  62% off  \n",
       "2     ₹379  62% off  \n",
       "3     ₹399  60% off  \n",
       "4     ₹473  68% off  \n",
       "..     ...      ...  \n",
       "95    ₹279  72% off  \n",
       "96    ₹379  72% off  \n",
       "97    ₹384  61% off  \n",
       "98    ₹199  60% off  \n",
       "99  ₹1,538  45% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.flipkart.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "log_in_pop_up = driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "log_in_pop_up.click()\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar=driver.find_element_by_class_name(\"_3704LK\")\n",
    "search_bar.clear()\n",
    "search_bar.send_keys('sneakers')\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "button=driver.find_element_by_class_name('L0Z3Pu')\n",
    "button.click()\n",
    "\n",
    "\n",
    "\n",
    "brand=[]\n",
    "description=[]\n",
    "price=[]\n",
    "discount=[]\n",
    "\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "start=0\n",
    "end=4\n",
    "for page in range(start,end):\n",
    "    brands=driver.find_elements_by_class_name('_2WkVRV')\n",
    "    for i in brands:\n",
    "        brand.append(i.text)\n",
    "    prices=driver.find_elements_by_xpath(\"//div[@class='_30jeq3']\")\n",
    "    for i in prices:\n",
    "        price.append(i.text)\n",
    "    disc=driver.find_elements_by_xpath(\"//div[@class='_3Ay6Sb']//span\")\n",
    "    for i in disc:\n",
    "        discount.append(i.text)\n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "        \n",
    "        \n",
    "time.sleep(2)        \n",
    "\n",
    "urls = []\n",
    "\n",
    "for page in range(0,4):\n",
    "    \n",
    "    product_url = driver.find_elements_by_xpath(\"//a[@class='_2UzuFa']\")\n",
    "    for i in product_url:\n",
    "        urls.append(i.get_attribute('href'))\n",
    "    \n",
    "    nxt_button=driver.find_elements_by_xpath(\"//a[@class='_1LKTO3']\")\n",
    "    try:\n",
    "        driver.get(nxt_button[1].get_attribute('href'))\n",
    "    except:\n",
    "        driver.get(nxt_button[0].get_attribute('href'))\n",
    "        \n",
    "time.sleep(2)        \n",
    "for i in urls:\n",
    "    driver.get(i)\n",
    "    desc=driver.find_elements_by_xpath('//span[@class=\"B_NuCI\"]')\n",
    "    for i in desc:\n",
    "        description.append(i.text)\n",
    "time.sleep(2)        \n",
    "time.sleep(3)        \n",
    "\n",
    "df=pd.DataFrame({'Brand':brand[:100],\n",
    "                'Description':description[:100],\n",
    "                'Price':price[:100],\n",
    "                'Discount':discount[:100]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this we found the 100 sneakers from flipkart with brand,price, description and discounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q9.\"https://www.myntra.com/shoes\". Set price filter \"Rs 6649 to Rs 13099\" and color filter to \"Black\" and then scrap 100 shoes data. The data should include \"Brand\" of shoes, shoe short-description and price. Please not: Everything should done through code even the filtering for sneakers as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-a79b82246094>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.myntra.com/shoes%22\"\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_button.click()\n",
    "\n",
    "\n",
    "black_color_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div\")\n",
    "black_color_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Short-description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Allen Cooper</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 939Rs. 4699(80% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Champs</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 599Rs. 799(25% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Flyer Beta Walking Shoes</td>\n",
       "      <td>Rs. 2279Rs. 3799(40% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DressBerry</td>\n",
       "      <td>Women Polka Dot Ballerinas</td>\n",
       "      <td>Rs. 524Rs. 1499(65% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Red Tape</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs. 1799Rs. 5999(70% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Azzaro Black</td>\n",
       "      <td>Men Zoom Winflo 8 Running</td>\n",
       "      <td>Rs. 759Rs. 1999(62% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>H&amp;M</td>\n",
       "      <td>Women Running Shoes</td>\n",
       "      <td>Rs. 1299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Semiformal Loafers</td>\n",
       "      <td>Rs. 3249Rs. 6499(50% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HRX by Hrithik Roshan</td>\n",
       "      <td>Men AIR ZOOM Running Shoes</td>\n",
       "      <td>Rs. 1539Rs. 2799(45% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Mactree</td>\n",
       "      <td>Men Formal Shoes</td>\n",
       "      <td>Rs. 649Rs. 2164(70% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Brand             Short-description  \\\n",
       "0            Allen Cooper             Men Running Shoes   \n",
       "1                  Champs             Men Running Shoes   \n",
       "2                    Puma  Men Flyer Beta Walking Shoes   \n",
       "3              DressBerry    Women Polka Dot Ballerinas   \n",
       "4                Red Tape             Men Walking Shoes   \n",
       "..                    ...                           ...   \n",
       "95           Azzaro Black     Men Zoom Winflo 8 Running   \n",
       "96                    H&M           Women Running Shoes   \n",
       "97                   Puma        Men Semiformal Loafers   \n",
       "98  HRX by Hrithik Roshan    Men AIR ZOOM Running Shoes   \n",
       "99                Mactree              Men Formal Shoes   \n",
       "\n",
       "                        Price  \n",
       "0    Rs. 939Rs. 4699(80% OFF)  \n",
       "1     Rs. 599Rs. 799(25% OFF)  \n",
       "2   Rs. 2279Rs. 3799(40% OFF)  \n",
       "3    Rs. 524Rs. 1499(65% OFF)  \n",
       "4   Rs. 1799Rs. 5999(70% OFF)  \n",
       "..                        ...  \n",
       "95   Rs. 759Rs. 1999(62% OFF)  \n",
       "96                   Rs. 1299  \n",
       "97  Rs. 3249Rs. 6499(50% OFF)  \n",
       "98  Rs. 1539Rs. 2799(45% OFF)  \n",
       "99   Rs. 649Rs. 2164(70% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "shoe_names=[]\n",
    "s_desc=[]\n",
    "short_desc=[]\n",
    "price=[]\n",
    "page_urls = []\n",
    "\n",
    "time.sleep(4)\n",
    "\n",
    "nxt_page = driver.find_elements_by_xpath(\"//li[@class='pagination-number']/a\")\n",
    "for i in nxt_page:\n",
    "    page_urls.append(i.get_attribute('href'))\n",
    "    \n",
    "\n",
    "for url in page_urls[:3]:\n",
    "    driver.get(url)\n",
    "    Names=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h3\")  \n",
    "    for i in Names:\n",
    "        shoe_names.append(i.text)\n",
    "    \n",
    "    desc=driver.find_elements_by_xpath(\"//div[@class='product-productMetaInfo']/h4\") \n",
    "    for i in desc:\n",
    "        s_desc.append(i.text)\n",
    "    \n",
    "    for j in range(0,len(s_desc),2):\n",
    "        short_desc.append(s_desc[j])\n",
    "    \n",
    "    rs=driver.find_elements_by_xpath(\"//div[@class='product-price']\")  \n",
    "    for i in rs:\n",
    "        price.append(i.text)    \n",
    "        \n",
    "df=pd.DataFrame({'Brand': shoe_names[:100],'Short-description': short_desc[:100],'Price': price[:100]})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we have scrapped top 100 shoe data with price, short description and brand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10: Go to webpage https://www.amazon.in/Enter “Laptop” in the search field and then click the search icon.Then set CPU Type filter to “Intel Core i7” and “Intel Core i9” After setting the filters scrape first 10 laptops data.You have to scrape 3 attributes for each laptop:\n",
    "1.title\n",
    "2.Ratings\n",
    "3.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-32-8a3214fe227c>:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:443: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:483: UserWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  warnings.warn(\"find_element_by_* commands are deprecated. Please use find_element() instead\")\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:502: UserWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  warnings.warn(\"find_elements_by_* commands are deprecated. Please use find_elements() instead\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...</td>\n",
       "      <td>79,646</td>\n",
       "      <td>3.8 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>84,990</td>\n",
       "      <td>4.5 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...</td>\n",
       "      <td>76,995</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell G3 3579 15.6-inch FHD Gaming Laptop (8th ...</td>\n",
       "      <td>89,898</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion Gaming 10th Gen Intel Core i7 Proc...</td>\n",
       "      <td>86,990</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>62,303</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>40,932</td>\n",
       "      <td>3.4 out of 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...</td>\n",
       "      <td>91,490</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MSI Creator 17, Intel i7-10875H, 17.3\" UHD HDR...</td>\n",
       "      <td>2,99,990</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...</td>\n",
       "      <td>92,400</td>\n",
       "      <td>NO rating</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title     Price       Ratings\n",
       "0  HP Pavilion x360 (2021) 14\" (35.56cms) FHD Tou...    79,646  3.8 out of 5\n",
       "1  HP Pavilion (2021) Thin & Light 11th Gen Core ...    84,990  4.5 out of 5\n",
       "2  ASUS VivoBook S S14 Intel Core i7-1165G7 11th ...    76,995  4.4 out of 5\n",
       "3  Dell G3 3579 15.6-inch FHD Gaming Laptop (8th ...    89,898  3.9 out of 5\n",
       "4  HP Pavilion Gaming 10th Gen Intel Core i7 Proc...    86,990  4.2 out of 5\n",
       "5  Mi Notebook Horizon Edition 14 Intel Core i7-1...    62,303  4.4 out of 5\n",
       "6  Life Digital Laptop 15.6-inch (39.62 cms) (Int...    40,932  3.4 out of 5\n",
       "7  (Renewed) Dell XPS Intel 8th Gen Core i7 13.3-...    91,490     NO rating\n",
       "8  MSI Creator 17, Intel i7-10875H, 17.3\" UHD HDR...  2,99,990     NO rating\n",
       "9  Dell Inspiron 5410 14\" FHD Touch Display 2in1 ...    92,400     NO rating"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome(\"C:\\\\Users\\\\HP\\\\Downloads\\\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "time.sleep(3)\n",
    "\n",
    "url = \"https://www.amazon.in/ref=nav_logo\"\n",
    "driver.get(url)\n",
    "\n",
    "\n",
    "\n",
    "Title=[]\n",
    "Ratings=[]\n",
    "price=[]\n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "search_bar = driver.find_element_by_id(\"twotabsearchtextbox\")    \n",
    "search_bar.clear()                                               \n",
    "search_bar.send_keys(\"laptops\")                                  \n",
    "search_button = driver.find_element_by_xpath('//span[@id=\"nav-search-submit-text\"]')       \n",
    "search_button.click()    \n",
    "\n",
    "time.sleep(2)\n",
    "\n",
    "filter_button=driver.find_elements_by_xpath(\"//a[@class='a-link-normal s-navigation-item']/span\")\n",
    "for i in filter_button:\n",
    "    if i.text=='Intel Core i7':\n",
    "        i.click()\n",
    "        break\n",
    "        \n",
    "        \n",
    "#Scrapping Titles\n",
    "titles=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "for i in titles[:10]:\n",
    "    Title.append(i.text)\n",
    "    \n",
    "    \n",
    "#scrapping Price\n",
    "prices=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "for i in prices[:10]:\n",
    "    price.append(i.text)\n",
    "\n",
    "#locating Ratings\n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "UR=[]\n",
    "for i in urls[:10]:\n",
    "    UR.append(i.get_attribute('href'))\n",
    "for url in UR:\n",
    "    driver.get(url)\n",
    "    try:                                                                      \n",
    "        rating=driver.find_element_by_xpath(\"//span[@class='a-size-base a-nowrap']//span\")\n",
    "        Ratings.append(rating.text)\n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Ratings.append(\"NO rating\")\n",
    "        \n",
    "\n",
    "df=pd.DataFrame({'Title':Title,\n",
    "                'Price':price,\n",
    "                'Ratings':Ratings})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this we have scraped top 10 laptops with their title, ratings and ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
